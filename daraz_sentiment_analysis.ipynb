{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOl4BSmzYi9rogFdzvIcOYT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VellummyilumVinoth/Aspect_based_sentimental_analysis/blob/main/daraz_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers\n",
        "! pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k06RTnMv3Ozp",
        "outputId": "315eadfd-16f6-4c1f-949b-12bd42c0288c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kRUAZuW4Fhk",
        "outputId": "0edaf53e-d0dd-435e-88a7-e7858d621d7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B9oHPiK2vGZ",
        "outputId": "fa970016-a90f-4d3c-f513-f839c4654886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import torch\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer, AutoModelForSequenceClassification, BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "def add_full_stop(text):\n",
        "    last_character = text[-1]\n",
        "    if last_character != \".\":\n",
        "        text += \".\"\n",
        "    return text\n",
        "\n",
        "# Read the CSV file and extract the comments column\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/zidan/daraz_predictions.csv\")\n",
        "comments = data[\"Review\"]\n",
        "category = data[\"Category\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kHZdr20MfDFS",
        "outputId": "335f8a6b-1c12-46c7-bb14-f44000125d4a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Product Name    Category  Rating  \\\n",
              "0                    Sunlight Care Detergent Liquid, 1L     Laundry     1.0   \n",
              "1                    Sunlight Care Detergent Liquid, 1L     Laundry     5.0   \n",
              "2                    Sunlight Care Detergent Liquid, 1L     Laundry     5.0   \n",
              "3                    Sunlight Care Detergent Liquid, 1L     Laundry     1.0   \n",
              "4                    Sunlight Care Detergent Liquid, 1L     Laundry     5.0   \n",
              "...                                                 ...         ...     ...   \n",
              "1837  Sustagen Nutritional Supplement Chocolate Flav...  MilkPowder     4.0   \n",
              "1838  Sustagen Nutritional Supplement Chocolate Flav...  MilkPowder     4.0   \n",
              "1839  Sustagen Nutritional Supplement Chocolate Flav...  MilkPowder     3.0   \n",
              "1840  Sustagen Nutritional Supplement Chocolate Flav...  MilkPowder     4.0   \n",
              "1841  Sustagen Nutritional Supplement Chocolate Flav...  MilkPowder     2.0   \n",
              "\n",
              "       Reviewer Name                                             Review  \\\n",
              "0           Eranga D  I purchased 2 bottles. Both seem partially use...   \n",
              "1          Suranga Y  Very fast & safe delivery . Neet packing. I wi...   \n",
              "2           Ishini F  Fast delivery during this pandemic. Got the pr...   \n",
              "3              Dr. K  Alot of liquid has leaked.im very much disappo...   \n",
              "4         Rajitha S.  Thank you very much !! I received my package t...   \n",
              "...              ...                                                ...   \n",
              "1837    by ******576              very good product value for the price   \n",
              "1838   by ruchira K.  Delivery within 1day to Tangalle... well packe...   \n",
              "1839  by Sivathas J.                      high quality reasonable price   \n",
              "1840   by Poornamith  Excellent packaging. And it was delivered quic...   \n",
              "1841      by Disnaka  It's not regarding product. all the canisters ...   \n",
              "\n",
              "                                   Review_without_emoji  \\\n",
              "0     I purchased 2 bottles. Both seem partially use...   \n",
              "1     Very fast & safe delivery . Neet packing. I wi...   \n",
              "2     Fast delivery during this pandemic. Got the pr...   \n",
              "3     Alot of liquid has leaked.im very much disappo...   \n",
              "4     Thank you very much !! I received my package t...   \n",
              "...                                                 ...   \n",
              "1837              very good product value for the price   \n",
              "1838  Delivery within 1day to Tangalle... well packe...   \n",
              "1839                      high quality reasonable price   \n",
              "1840  Excellent packaging. And it was delivered quic...   \n",
              "1841  It's not regarding product. all the canisters ...   \n",
              "\n",
              "                                        preprocess_text  \\\n",
              "0     i purchased 2 bottles both seem partially used...   \n",
              "1     very fast  safe delivery  neet packing i wish ...   \n",
              "2     fast delivery during this pandemic got the pro...   \n",
              "3     alot of liquid has leakedim very much disappoi...   \n",
              "4     thank you very much  i received my package tod...   \n",
              "...                                                 ...   \n",
              "1837              very good product value for the price   \n",
              "1838  delivery within 1day to tangalle well packedco...   \n",
              "1839                      high quality reasonable price   \n",
              "1840  excellent packaging and it was delivered quick...   \n",
              "1841  its not regarding product all the canisters da...   \n",
              "\n",
              "                                       preprocess_text1  price  quality  \\\n",
              "0     ['purchased', '2', 'bottles', 'seem', 'partial...      1        1   \n",
              "1     ['fast', 'safe', 'delivery', 'neet', 'packing'...      1        0   \n",
              "2     ['fast', 'delivery', 'pandemic', 'got', 'produ...      0        0   \n",
              "3     ['alot', 'liquid', 'leakedim', 'much', 'disapp...      0        0   \n",
              "4     ['thank', 'much', 'received', 'package', 'toda...      0        0   \n",
              "...                                                 ...    ...      ...   \n",
              "1837              ['good', 'product', 'value', 'price']      1        0   \n",
              "1838  ['delivery', 'within', '1day', 'tangalle', 'we...      1        0   \n",
              "1839         ['high', 'quality', 'reasonable', 'price']      1        1   \n",
              "1840  ['excellent', 'packaging', 'delivered', 'quick...      1        1   \n",
              "1841  ['regarding', 'product', 'canisters', 'damaged...      0        0   \n",
              "\n",
              "      delivery cost  packaging  design  customer service  usability  \n",
              "0                 0          1       0                 0          1  \n",
              "1                 1          1       0                 0          0  \n",
              "2                 1          1       0                 1          0  \n",
              "3                 0          1       0                 0          0  \n",
              "4                 1          1       0                 1          0  \n",
              "...             ...        ...     ...               ...        ...  \n",
              "1837              0          0       0                 0          0  \n",
              "1838              1          1       0                 1          0  \n",
              "1839              0          0       0                 0          0  \n",
              "1840              1          1       0                 1          0  \n",
              "1841              0          1       0                 0          0  \n",
              "\n",
              "[1842 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecc8871f-81bb-46a8-a02c-65cd9c7edbeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Category</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviewer Name</th>\n",
              "      <th>Review</th>\n",
              "      <th>Review_without_emoji</th>\n",
              "      <th>preprocess_text</th>\n",
              "      <th>preprocess_text1</th>\n",
              "      <th>price</th>\n",
              "      <th>quality</th>\n",
              "      <th>delivery cost</th>\n",
              "      <th>packaging</th>\n",
              "      <th>design</th>\n",
              "      <th>customer service</th>\n",
              "      <th>usability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sunlight Care Detergent Liquid, 1L</td>\n",
              "      <td>Laundry</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Eranga D</td>\n",
              "      <td>I purchased 2 bottles. Both seem partially use...</td>\n",
              "      <td>I purchased 2 bottles. Both seem partially use...</td>\n",
              "      <td>i purchased 2 bottles both seem partially used...</td>\n",
              "      <td>['purchased', '2', 'bottles', 'seem', 'partial...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sunlight Care Detergent Liquid, 1L</td>\n",
              "      <td>Laundry</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Suranga Y</td>\n",
              "      <td>Very fast &amp; safe delivery . Neet packing. I wi...</td>\n",
              "      <td>Very fast &amp; safe delivery . Neet packing. I wi...</td>\n",
              "      <td>very fast  safe delivery  neet packing i wish ...</td>\n",
              "      <td>['fast', 'safe', 'delivery', 'neet', 'packing'...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sunlight Care Detergent Liquid, 1L</td>\n",
              "      <td>Laundry</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Ishini F</td>\n",
              "      <td>Fast delivery during this pandemic. Got the pr...</td>\n",
              "      <td>Fast delivery during this pandemic. Got the pr...</td>\n",
              "      <td>fast delivery during this pandemic got the pro...</td>\n",
              "      <td>['fast', 'delivery', 'pandemic', 'got', 'produ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sunlight Care Detergent Liquid, 1L</td>\n",
              "      <td>Laundry</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Dr. K</td>\n",
              "      <td>Alot of liquid has leaked.im very much disappo...</td>\n",
              "      <td>Alot of liquid has leaked.im very much disappo...</td>\n",
              "      <td>alot of liquid has leakedim very much disappoi...</td>\n",
              "      <td>['alot', 'liquid', 'leakedim', 'much', 'disapp...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sunlight Care Detergent Liquid, 1L</td>\n",
              "      <td>Laundry</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Rajitha S.</td>\n",
              "      <td>Thank you very much !! I received my package t...</td>\n",
              "      <td>Thank you very much !! I received my package t...</td>\n",
              "      <td>thank you very much  i received my package tod...</td>\n",
              "      <td>['thank', 'much', 'received', 'package', 'toda...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1837</th>\n",
              "      <td>Sustagen Nutritional Supplement Chocolate Flav...</td>\n",
              "      <td>MilkPowder</td>\n",
              "      <td>4.0</td>\n",
              "      <td>by ******576</td>\n",
              "      <td>very good product value for the price</td>\n",
              "      <td>very good product value for the price</td>\n",
              "      <td>very good product value for the price</td>\n",
              "      <td>['good', 'product', 'value', 'price']</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1838</th>\n",
              "      <td>Sustagen Nutritional Supplement Chocolate Flav...</td>\n",
              "      <td>MilkPowder</td>\n",
              "      <td>4.0</td>\n",
              "      <td>by ruchira K.</td>\n",
              "      <td>Delivery within 1day to Tangalle... well packe...</td>\n",
              "      <td>Delivery within 1day to Tangalle... well packe...</td>\n",
              "      <td>delivery within 1day to tangalle well packedco...</td>\n",
              "      <td>['delivery', 'within', '1day', 'tangalle', 'we...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1839</th>\n",
              "      <td>Sustagen Nutritional Supplement Chocolate Flav...</td>\n",
              "      <td>MilkPowder</td>\n",
              "      <td>3.0</td>\n",
              "      <td>by Sivathas J.</td>\n",
              "      <td>high quality reasonable price</td>\n",
              "      <td>high quality reasonable price</td>\n",
              "      <td>high quality reasonable price</td>\n",
              "      <td>['high', 'quality', 'reasonable', 'price']</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1840</th>\n",
              "      <td>Sustagen Nutritional Supplement Chocolate Flav...</td>\n",
              "      <td>MilkPowder</td>\n",
              "      <td>4.0</td>\n",
              "      <td>by Poornamith</td>\n",
              "      <td>Excellent packaging. And it was delivered quic...</td>\n",
              "      <td>Excellent packaging. And it was delivered quic...</td>\n",
              "      <td>excellent packaging and it was delivered quick...</td>\n",
              "      <td>['excellent', 'packaging', 'delivered', 'quick...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1841</th>\n",
              "      <td>Sustagen Nutritional Supplement Chocolate Flav...</td>\n",
              "      <td>MilkPowder</td>\n",
              "      <td>2.0</td>\n",
              "      <td>by Disnaka</td>\n",
              "      <td>It's not regarding product. all the canisters ...</td>\n",
              "      <td>It's not regarding product. all the canisters ...</td>\n",
              "      <td>its not regarding product all the canisters da...</td>\n",
              "      <td>['regarding', 'product', 'canisters', 'damaged...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1842 rows Ã— 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecc8871f-81bb-46a8-a02c-65cd9c7edbeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecc8871f-81bb-46a8-a02c-65cd9c7edbeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecc8871f-81bb-46a8-a02c-65cd9c7edbeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer and model for T5 text generation\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"flax-community/t5-base-wikisplit\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"flax-community/t5-base-wikisplit\")\n",
        "\n",
        "# Initialize tokenizer and model for aspect sentiment analysis\n",
        "aspect_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "aspect_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# Initialize tokenizer and model for aspect classification\n",
        "classification_model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/zidan/finetuned_bert', num_labels=7)\n",
        "classification_tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/zidan/finetuned_bert', do_lower_case=True)\n",
        "\n",
        "def assign_sentiment_label(sentiment_score):\n",
        "    if sentiment_score >= 0.99983:\n",
        "        sentiment_label = 'very good'\n",
        "    elif sentiment_score >= 0.999:\n",
        "        sentiment_label = 'good'\n",
        "    elif sentiment_score > 0.001:\n",
        "        sentiment_label = 'neutral'\n",
        "    elif sentiment_score > 0.0002:\n",
        "        sentiment_label = 'bad'\n",
        "    else:\n",
        "        sentiment_label = 'poor'\n",
        "    return sentiment_label\n",
        "\n",
        "\n",
        "# Define aspect labels\n",
        "aspect_labels = [\"price\", \"quality\", \"delivery cost\", \"packaging\", \"design\", \"customer service\", \"usability\"]\n",
        "\n",
        "# Initialize spaCy for sentence tokenization\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdIY8aDuKe03",
        "outputId": "d03a5cdd-537c-4acf-9f9e-e01f3cffe630"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the results list to store the processed data\n",
        "results = []\n",
        "\n",
        "# Process each comment and its sentences\n",
        "for comment in comments:\n",
        "    sentences = sent_tokenize(comment)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Add full stop if necessary\n",
        "        input_sentence = add_full_stop(sentence)\n",
        "\n",
        "        # Tokenize and generate simple sentences using T5 model\n",
        "        encoder_max_length = 256\n",
        "        decoder_max_length = 256\n",
        "        complex_tokenized = tokenizer(input_sentence, padding=\"max_length\", truncation=True, max_length=encoder_max_length, return_tensors='pt')\n",
        "        simple_tokenized = model.generate(complex_tokenized['input_ids'], attention_mask=complex_tokenized['attention_mask'], max_length=decoder_max_length, num_beams=5)\n",
        "        simple_sentences = tokenizer.batch_decode(simple_tokenized, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "        # Perform aspect classification\n",
        "        input_statements = [statement.strip() for statement in simple_sentences if statement.strip()]\n",
        "\n",
        "        encoded_inputs = classification_tokenizer.batch_encode_plus(\n",
        "            input_statements,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            classification_model.eval()\n",
        "            outputs = classification_model(**encoded_inputs)\n",
        "            predicted_labels = outputs.logits\n",
        "\n",
        "        predicted_labels = (torch.sigmoid(predicted_labels) > 0.5).to(torch.int).tolist()\n",
        "\n",
        "        # Perform aspect sentiment analysis for each aspect\n",
        "        aspect_sentiment_labels = {}\n",
        "        aspect_sentiment_scores = {}\n",
        "\n",
        "        for aspect_label in aspect_labels:\n",
        "            aspect_sentiment_labels[aspect_label] = []\n",
        "            aspect_sentiment_scores[aspect_label] = []\n",
        "\n",
        "        for statement_index, statement in enumerate(input_statements):\n",
        "            for aspect_index, aspect_label in enumerate(aspect_labels):\n",
        "                if predicted_labels[statement_index][aspect_index] == 1:\n",
        "                    inputs = aspect_tokenizer.encode_plus(statement, add_special_tokens=True, return_tensors=\"pt\")\n",
        "                    input_ids = inputs[\"input_ids\"]\n",
        "                    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        outputs = aspect_model(input_ids, attention_mask=attention_mask)\n",
        "                        logits = outputs.logits\n",
        "\n",
        "                    probabilities = torch.softmax(logits, dim=1)\n",
        "                    sentiment_score = probabilities[0][1].item()  # Positive sentiment score\n",
        "                    sentiment_label = assign_sentiment_label(sentiment_score)\n",
        "\n",
        "                    aspect_sentiment_labels[aspect_label].append(sentiment_label)\n",
        "                    aspect_sentiment_scores[aspect_label].append(sentiment_score)\n",
        "                else:\n",
        "                    aspect_sentiment_labels[aspect_label].append(\"-\")\n",
        "                    aspect_sentiment_scores[aspect_label].append(\"-\")\n",
        "\n",
        "        # Calculate the average sentiment score for each aspect\n",
        "        overall_sentiment_scores = []\n",
        "        for aspect_label in aspect_labels:\n",
        "            numeric_scores = [score for score in aspect_sentiment_scores[aspect_label] if isinstance(score, float)]\n",
        "            if numeric_scores:\n",
        "                aspect_sentiment_scores[aspect_label] = sum(numeric_scores) / len(numeric_scores)\n",
        "            else:\n",
        "                aspect_sentiment_scores[aspect_label] = \"-\"\n",
        "\n",
        "        # Calculate the overall sentiment label and score for the input sentence\n",
        "        numeric_scores = [score for score in aspect_sentiment_scores.values() if isinstance(score, float)]\n",
        "        if numeric_scores:\n",
        "            overall_sentiment_score = sum(numeric_scores) / len(numeric_scores)\n",
        "            overall_sentiment_label = assign_sentiment_label(overall_sentiment_score)\n",
        "        else:\n",
        "            overall_sentiment_score = \"-\"\n",
        "            overall_sentiment_label = \"-\"\n",
        "\n",
        "        # Store the result in a dictionary\n",
        "        result = {\n",
        "            \"Comment\": comment,\n",
        "            \"Category\": category,\n",
        "            \"Sentence\": input_sentence,\n",
        "            \"Overall Sentiment Score\": overall_sentiment_score,\n",
        "            \"Overall Sentiment Label\": overall_sentiment_label,\n",
        "        }\n",
        "\n",
        "        # Calculate the average sentiment label for each aspect\n",
        "        average_sentiment_labels = {}\n",
        "        for aspect_label in aspect_labels:\n",
        "            sentiment_labels = [label for label in aspect_sentiment_labels[aspect_label] if label != \"-\"]\n",
        "            if sentiment_labels:\n",
        "                average_sentiment_labels[aspect_label] = max(set(sentiment_labels), key=sentiment_labels.count)\n",
        "            else:\n",
        "                average_sentiment_labels[aspect_label] = \"-\"\n",
        "\n",
        "            # Add aspect sentiment label to the result dictionary\n",
        "            result[aspect_label] = average_sentiment_labels[aspect_label]\n",
        "\n",
        "        # Append the result to the results list\n",
        "        results.append(result)\n",
        "\n",
        "# Create DataFrame from the results list\n",
        "result_df = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "HBsfmw8LatJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "_y7JEiF1bT3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1# Create an empty dictionary to store the results for each comment\n",
        "comment_results = {}\n",
        "\n",
        "# Iterate over the results\n",
        "for result in results:\n",
        "    comment = result['Comment']\n",
        "    category = result['Category']\n",
        "\n",
        "    # Check if the comment is already in the dictionary\n",
        "    if comment in comment_results:\n",
        "        # Update the overall sentiment score and label\n",
        "        overall_sentiment_score = comment_results[comment]['Overall Sentiment Score']\n",
        "        overall_sentiment_label = comment_results[comment]['Overall Sentiment Label']\n",
        "        num_results = comment_results[comment]['Num Results']\n",
        "\n",
        "        # Convert sentiment scores to float if necessary\n",
        "        overall_sentiment_score = float(overall_sentiment_score)\n",
        "        new_sentiment_score = float(result['Overall Sentiment Score']) if result['Overall Sentiment Score'] != '-' else 0.0\n",
        "\n",
        "        # Calculate the running average for the sentiment score\n",
        "        overall_sentiment_score = (overall_sentiment_score * num_results + new_sentiment_score) / (num_results + 1)\n",
        "\n",
        "        # Update the overall sentiment label if necessary\n",
        "        if result['Overall Sentiment Label'] != '-':\n",
        "            overall_sentiment_label = result['Overall Sentiment Label']\n",
        "\n",
        "        # Update the comment's result with the updated values\n",
        "        comment_results[comment]['Overall Sentiment Score'] = overall_sentiment_score\n",
        "        comment_results[comment]['Overall Sentiment Label'] = overall_sentiment_label\n",
        "        comment_results[comment]['Num Results'] += 1\n",
        "\n",
        "        # Update the aspect sentiment labels\n",
        "        for aspect_label in aspect_labels:\n",
        "            if result[aspect_label] != '-':\n",
        "                comment_results[comment][aspect_label].append(result[aspect_label])\n",
        "\n",
        "    else:\n",
        "        # Create a new entry for the comment in the dictionary\n",
        "        comment_results[comment] = {\n",
        "            'Comment': comment,\n",
        "            \"Category\": category,\n",
        "            'Overall Sentiment Score': float(result['Overall Sentiment Score']) if result['Overall Sentiment Score'] != '-' else 0.0,\n",
        "            'Overall Sentiment Label': result['Overall Sentiment Label'],\n",
        "            'Num Results': 1,\n",
        "        }\n",
        "\n",
        "        # Initialize the aspect sentiment labels\n",
        "        for aspect_label in aspect_labels:\n",
        "            if result[aspect_label] != '-':\n",
        "                comment_results[comment][aspect_label] = [result[aspect_label]]\n",
        "            else:\n",
        "                comment_results[comment][aspect_label] = []\n",
        "\n",
        "# Create a list to store the final results\n",
        "final_results = []\n",
        "\n",
        "# Convert the comment results dictionary into a list of dictionaries\n",
        "for comment_result in comment_results.values():\n",
        "    # Calculate the average sentiment label for each aspect\n",
        "    average_sentiment_labels = {}\n",
        "    for aspect_label in aspect_labels:\n",
        "        sentiment_labels = comment_result[aspect_label]\n",
        "        if sentiment_labels:\n",
        "            average_sentiment_labels[aspect_label] = max(set(sentiment_labels), key=sentiment_labels.count)\n",
        "        else:\n",
        "            average_sentiment_labels[aspect_label] = \"-\"\n",
        "\n",
        "    # Create the final result dictionary for the comment\n",
        "    final_result = {\n",
        "        'Comment': comment_result['Comment'],\n",
        "        \"Category\": comment_result['Category'],\n",
        "        'Overall Sentiment Score': comment_result['Overall Sentiment Score'],\n",
        "        'Overall Sentiment Label': comment_result['Overall Sentiment Label'],\n",
        "    }\n",
        "\n",
        "    # Add the aspect sentiment labels to the final result dictionary\n",
        "    for aspect_label in aspect_labels:\n",
        "        final_result[aspect_label] = average_sentiment_labels[aspect_label]\n",
        "\n",
        "    # Append the final result to the list\n",
        "    final_results.append(final_result)\n",
        "\n",
        "# Create DataFrame from the final results list\n",
        "result_df = pd.DataFrame(final_results, columns=[\"Comment\",\"Category\" ,\"Overall Sentiment Score\", \"Overall Sentiment Label\"] + aspect_labels)\n",
        "result_df.to_csv('/content/drive/MyDrive/zidan/daraz_sentiment_analysis.csv', index=False)\n"
      ],
      "metadata": {
        "id": "nwtrallnKbL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "LBX36UU7Kjfz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}